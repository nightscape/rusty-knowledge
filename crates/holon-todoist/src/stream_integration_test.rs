//! Integration tests for stream-based external system integration
//!
//! Tests verify:
//! - Stream propagation from Provider to Cache
//! - Cache behavior (reads from cache, writes delegate to datasource)
//! - Fake datasource emits changes correctly
//! - End-to-end flow with stream updates

#[cfg(test)]
#[cfg(feature = "integration-tests")]
mod tests {
    use std::collections::HashMap;
    use std::sync::Arc;
    use std::time::Duration;
    use tokio::sync::RwLock;
    use tokio::time::sleep;

    use holon::core::datasource::{Change, CrudOperations, DataSource};
    use holon::core::StreamCache as QueryableCache;
    use holon::storage::backend::StorageBackend;
    use holon::storage::turso::TursoBackend;
    use holon_api::Value;

    use crate::fake::TodoistTaskFake;
    use crate::models::TodoistTask;

    /// Simple in-memory DataSource for testing
    struct InMemoryDataSource {
        tasks: Arc<RwLock<HashMap<String, TodoistTask>>>,
    }

    impl InMemoryDataSource {
        fn new() -> Self {
            Self {
                tasks: Arc::new(RwLock::new(HashMap::new())),
            }
        }

        /// Update task from change stream (called by test helper)
        async fn apply_change(&self, change: Change<TodoistTask>) {
            let mut tasks = self.tasks.write().await;
            match change {
                Change::Created { data, .. } | Change::Updated { data, .. } => {
                    tasks.insert(data.id.clone(), data);
                }
                Change::Deleted { id, .. } => {
                    tasks.remove(&id);
                }
            }
        }
    }

    #[async_trait::async_trait]
    impl DataSource<TodoistTask> for InMemoryDataSource {
        async fn get_all(&self) -> holon::core::datasource::Result<Vec<TodoistTask>> {
            Ok(self.tasks.read().await.values().cloned().collect())
        }

        async fn get_by_id(
            &self,
            id: &str,
        ) -> holon::core::datasource::Result<Option<TodoistTask>> {
            Ok(self.tasks.read().await.get(id).cloned())
        }
    }

    /// Helper to create a TodoistTaskFake with an in-memory cache that consumes changes
    async fn create_fake_with_cache() -> (Arc<TodoistTaskFake>, Arc<InMemoryDataSource>) {
        let cache = Arc::new(InMemoryDataSource::new());
        let fake = Arc::new(TodoistTaskFake::new(
            Arc::clone(&cache) as Arc<dyn DataSource<TodoistTask>>
        ));

        // Spawn background task to consume changes and update cache
        let cache_clone = Arc::clone(&cache);
        let mut rx = fake.subscribe();
        tokio::spawn(async move {
            while let Ok(changes) = rx.recv().await {
                for change in changes {
                    cache_clone.apply_change(change).await;
                }
            }
        });

        // Give the background task a moment to start
        sleep(Duration::from_millis(10)).await;

        (fake, cache)
    }

    /// Test that fake datasource emits changes on broadcast channel
    #[tokio::test]
    async fn test_fake_datasource_stream_emission() {
        let (fake, _cache) = create_fake_with_cache().await;
        let mut rx = fake.subscribe();

        // Create a task
        let mut fields = HashMap::new();
        fields.insert(
            "content".to_string(),
            Value::String("Test Task".to_string()),
        );
        fields.insert(
            "project_id".to_string(),
            Value::String("project-123".to_string()),
        );

        let id = fake.create(fields).await.unwrap();

        // Wait a bit for the change to propagate
        sleep(Duration::from_millis(100)).await;

        // Check that change was emitted (as a batch)
        let change = rx.try_recv();
        assert!(change.is_ok(), "Expected change batch to be emitted");
        let changes = change.unwrap();
        assert_eq!(changes.len(), 1);
        match &changes[0] {
            Change::Created { data, .. } => {
                assert_eq!(data.id, id);
                assert_eq!(data.content, "Test Task");
            }
            Change::Updated { .. } | Change::Deleted { .. } => {
                panic!("Expected Created, got {:?}", changes[0])
            }
        }
    }

    /// Test that cache reads from local database
    #[tokio::test]
    async fn test_cache_reads_from_local_db() {
        let (fake, _cache) = create_fake_with_cache().await;
        let db = Arc::new(RwLock::new(
            Box::new(TursoBackend::new_in_memory().await.unwrap()) as Box<dyn StorageBackend>,
        ));

        let cache = Arc::new(QueryableCache::new(
            fake.clone(),
            db,
            "todoist_tasks".to_string(),
        ));

        // Create a task via fake
        let mut fields = HashMap::new();
        fields.insert(
            "content".to_string(),
            Value::String("Cache Test Task".to_string()),
        );
        fields.insert(
            "project_id".to_string(),
            Value::String("project-123".to_string()),
        );

        let id = fake.create(fields).await.unwrap();

        // Wire up stream ingestion
        let mut rx = fake.subscribe();
        cache.ingest_stream(rx);

        // Wait for stream ingestion
        sleep(Duration::from_millis(200)).await;

        // Read from cache (should read from local DB)
        let task = cache.get_by_id(&id).await.unwrap();
        assert!(task.is_some(), "Task should be in cache");
        let task = task.unwrap();
        assert_eq!(task.content, "Cache Test Task");
    }

    /// Test that cache delegates writes to datasource
    #[tokio::test]
    async fn test_cache_delegates_writes() {
        let (fake, _cache) = create_fake_with_cache().await;
        let db = Arc::new(RwLock::new(
            Box::new(TursoBackend::new_in_memory().await.unwrap()) as Box<dyn StorageBackend>,
        ));

        let cache = Arc::new(QueryableCache::new(
            fake.clone(),
            db,
            "todoist_tasks".to_string(),
        ));

        // Wire up stream ingestion
        let mut rx = fake.subscribe();
        cache.ingest_stream(rx);

        // Create via cache (delegates to fake)
        let mut fields = HashMap::new();
        fields.insert(
            "content".to_string(),
            Value::String("Write Test Task".to_string()),
        );
        fields.insert(
            "project_id".to_string(),
            Value::String("project-123".to_string()),
        );

        let id = cache.create(fields).await.unwrap();

        // Wait for stream ingestion
        sleep(Duration::from_millis(200)).await;

        // Verify task is in cache (via stream update)
        let task = cache.get_by_id(&id).await.unwrap();
        assert!(task.is_some(), "Task should be in cache after write");
        let task = task.unwrap();
        assert_eq!(task.content, "Write Test Task");
    }

    /// Test that cache updates arrive via stream after write
    #[tokio::test]
    async fn test_cache_updates_via_stream() {
        let (fake, _cache) = create_fake_with_cache().await;
        let db = Arc::new(RwLock::new(
            Box::new(TursoBackend::new_in_memory().await.unwrap()) as Box<dyn StorageBackend>,
        ));

        let cache = Arc::new(QueryableCache::new(
            fake.clone(),
            db,
            "todoist_tasks".to_string(),
        ));

        // Wire up stream ingestion
        let mut rx = fake.subscribe();
        cache.ingest_stream(rx);

        // Create a task
        let mut fields = HashMap::new();
        fields.insert(
            "content".to_string(),
            Value::String("Original Content".to_string()),
        );
        fields.insert(
            "project_id".to_string(),
            Value::String("project-123".to_string()),
        );

        let id = cache.create(fields).await.unwrap();

        // Wait for initial creation
        sleep(Duration::from_millis(200)).await;

        // Update via cache (delegates to fake, update arrives via stream)
        cache
            .set_field(&id, "content", Value::String("Updated Content".to_string()))
            .await
            .unwrap();

        // Wait for stream update
        sleep(Duration::from_millis(200)).await;

        // Verify update is in cache
        let task = cache.get_by_id(&id).await.unwrap().unwrap();
        assert_eq!(task.content, "Updated Content");
    }

    /// Test provider â†’ cache stream flow
    #[tokio::test]
    async fn test_provider_cache_stream_flow() {
        // Create fake datasource
        let (fake, _cache) = create_fake_with_cache().await;
        let db = Arc::new(RwLock::new(
            Box::new(TursoBackend::new_in_memory().await.unwrap()) as Box<dyn StorageBackend>,
        ));

        // Create cache
        let cache = Arc::new(QueryableCache::new(
            fake.clone(),
            db,
            "todoist_tasks".to_string(),
        ));

        // Note: TodoistProvider test removed as it requires stream_provider module
        // which doesn't exist. This test can be re-added when provider is implemented.
        // For now, just verify cache can be created
        assert!(cache.get_all().await.is_ok());
    }

    /// Test multiple caches receiving same stream
    #[tokio::test]
    async fn test_multiple_caches_same_stream() {
        let (fake, _cache) = create_fake_with_cache().await;

        // Create two caches
        let db1 = Arc::new(RwLock::new(
            Box::new(TursoBackend::new_in_memory().await.unwrap()) as Box<dyn StorageBackend>,
        ));
        let cache1 = Arc::new(QueryableCache::new(
            fake.clone(),
            db1,
            "todoist_tasks_1".to_string(),
        ));

        let db2 = Arc::new(RwLock::new(
            Box::new(TursoBackend::new_in_memory().await.unwrap()) as Box<dyn StorageBackend>,
        ));
        let cache2 = Arc::new(QueryableCache::new(
            fake.clone(),
            db2,
            "todoist_tasks_2".to_string(),
        ));

        // Wire up both caches to same stream
        let mut rx1 = fake.subscribe();
        let mut rx2 = fake.subscribe();
        cache1.ingest_stream(rx1);
        cache2.ingest_stream(rx2);

        // Create a task
        let mut fields = HashMap::new();
        fields.insert(
            "content".to_string(),
            Value::String("Multi Cache Task".to_string()),
        );
        fields.insert(
            "project_id".to_string(),
            Value::String("project-123".to_string()),
        );

        let id = fake.create(fields).await.unwrap();

        // Wait for stream propagation
        sleep(Duration::from_millis(300)).await;

        // Verify both caches have the task
        let task1 = cache1.get_by_id(&id).await.unwrap();
        assert!(task1.is_some(), "Task should be in cache1");
        assert_eq!(task1.unwrap().content, "Multi Cache Task");

        let task2 = cache2.get_by_id(&id).await.unwrap();
        assert!(task2.is_some(), "Task should be in cache2");
        assert_eq!(task2.unwrap().content, "Multi Cache Task");
    }

    /// Test delete operation and stream propagation
    #[tokio::test]
    async fn test_delete_via_stream() {
        let (fake, _cache) = create_fake_with_cache().await;
        let db = Arc::new(RwLock::new(
            Box::new(TursoBackend::new_in_memory().await.unwrap()) as Box<dyn StorageBackend>,
        ));

        let cache = Arc::new(QueryableCache::new(
            fake.clone(),
            db,
            "todoist_tasks".to_string(),
        ));

        // Wire up stream ingestion
        let mut rx = fake.subscribe();
        cache.ingest_stream(rx);

        // Create a task
        let mut fields = HashMap::new();
        fields.insert(
            "content".to_string(),
            Value::String("To Delete".to_string()),
        );
        fields.insert(
            "project_id".to_string(),
            Value::String("project-123".to_string()),
        );

        let id = cache.create(fields).await.unwrap();

        // Wait for creation
        sleep(Duration::from_millis(200)).await;

        // Verify task exists
        assert!(cache.get_by_id(&id).await.unwrap().is_some());

        // Delete via cache
        cache.delete(&id).await.unwrap();

        // Wait for deletion stream
        sleep(Duration::from_millis(200)).await;

        // Verify task is deleted from cache
        assert!(cache.get_by_id(&id).await.unwrap().is_none());
    }

    /// Test that get_all returns all tasks from cache
    #[tokio::test]
    async fn test_cache_get_all() {
        let (fake, _cache) = create_fake_with_cache().await;
        let db = Arc::new(RwLock::new(
            Box::new(TursoBackend::new_in_memory().await.unwrap()) as Box<dyn StorageBackend>,
        ));

        let cache = Arc::new(QueryableCache::new(
            fake.clone(),
            db,
            "todoist_tasks".to_string(),
        ));

        // Wire up stream ingestion
        let mut rx = fake.subscribe();
        cache.ingest_stream(rx);

        // Create multiple tasks
        for i in 0..5 {
            let mut fields = HashMap::new();
            fields.insert("content".to_string(), Value::String(format!("Task {}", i)));
            fields.insert(
                "project_id".to_string(),
                Value::String("project-123".to_string()),
            );
            cache.create(fields).await.unwrap();
        }

        // Wait for all creations
        sleep(Duration::from_millis(500)).await;

        // Get all tasks
        let all_tasks = cache.get_all().await.unwrap();
        assert_eq!(all_tasks.len(), 5, "Should have 5 tasks");
    }
}
